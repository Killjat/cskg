#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘ç½‘é¡µå…‹éš†å·¥å…·å‘é€URLå…‹éš†è¯·æ±‚çš„è„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
1. æ”¯æŒå•ä¸ªURLå…‹éš†
2. æ”¯æŒä»æ–‡ä»¶æ‰¹é‡å…‹éš†URL
3. æ”¯æŒé‡è¯•æœºåˆ¶
4. æ”¯æŒä¿å­˜ç»“æœåˆ°æ–‡ä»¶
5. è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæç¤º
6. æ”¯æŒä¸åŒè¾“å‡ºæ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
  å•ä¸ªURLï¼špython send_clone_request.py <ç¨‹åºéƒ¨ç½²URL> <ç›®æ ‡å…‹éš†URL>
  æ‰¹é‡å¤„ç†ï¼špython send_clone_request.py <ç¨‹åºéƒ¨ç½²URL> --file <URLåˆ—è¡¨æ–‡ä»¶>
  ä¿å­˜ç»“æœï¼špython send_clone_request.py <ç¨‹åºéƒ¨ç½²URL> <ç›®æ ‡å…‹éš†URL> --output <è¾“å‡ºæ–‡ä»¶>

ç¤ºä¾‹ï¼š
  python send_clone_request.py http://localhost:5001 https://example.com
  python send_clone_request.py http://localhost:5001 --file urls.txt
  python send_clone_request.py http://localhost:5001 https://example.com --output result.txt
"""

import sys
import requests
import json
import time
import argparse
from typing import List, Dict, Optional


def send_clone_request(
    server_url: str, 
    target_url: str, 
    retries: int = 3, 
    delay: int = 2
) -> Dict[str, any]:
    """
    å‘å…‹éš†æœåŠ¡å™¨å‘é€URLè¯·æ±‚å¹¶è¿”å›å…‹éš†ç»“æœ
    
    Args:
        server_url: å…‹éš†æœåŠ¡å™¨URL
        target_url: ç›®æ ‡å…‹éš†URL
        retries: é‡è¯•æ¬¡æ•°
        delay: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        
    Returns:
        åŒ…å«å…‹éš†ç»“æœçš„å­—å…¸
    """
    for attempt in range(retries):
        try:
            # æ„å»ºAPIç«¯ç‚¹
            api_url = f"{server_url}/api/clone"
            
            print(f"ğŸš€ æ­£åœ¨å‘æœåŠ¡å™¨å‘é€è¯·æ±‚... (å°è¯• {attempt + 1}/{retries})")
            print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {server_url}")
            print(f"ğŸ¯ ç›®æ ‡URL: {target_url}")
            print()
            
            # å‘é€POSTè¯·æ±‚
            response = requests.post(
                api_url,
                json={"url": target_url},
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response.raise_for_status()
            
            # è§£æå“åº”
            result = response.json()
            
            if result.get("success"):
                # æœåŠ¡å™¨å·²ç»è¿”å›äº†ç›´æ¥å¯è®¿é—®çš„URL
                return {
                    'success': True,
                    'result': result
                }
            else:
                return {
                    'success': False,
                    'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                }
                
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:
                print(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                print(f"â±ï¸ å°†åœ¨ {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
                print()
            else:
                return {
                    'success': False,
                    'error': f"è¯·æ±‚å¤±è´¥: {str(e)}"
                }
        except json.JSONDecodeError as e:
            return {
                'success': False,
                'error': f"å“åº”è§£æå¤±è´¥: {str(e)}"
            }
    
    return {
        'success': False,
        'error': "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"
    }


def format_result(result: Dict[str, any], verbose: bool = True) -> str:
    """æ ¼å¼åŒ–å…‹éš†ç»“æœ"""
    if result['success']:
        info = result['result']
        
        # ç›´æ¥ä½¿ç”¨æœåŠ¡å™¨è¿”å›çš„URL
        access_url = info.get('access_url')
        full_url = info.get('full_url')
        info_url = info.get('info_url')
        
        if verbose:
            output = []
            output.append("âœ… å…‹éš†æˆåŠŸï¼")
            output.append(f"ğŸ“„ æ ‡é¢˜: {info.get('title')}")
            output.append(f"ğŸ’¾ ä¿å­˜ç›®å½•: {info.get('save_dir')}")
            output.append("")
            output.append("ğŸ“‹ å…‹éš†åçš„è®¿é—®åœ°å€:")
            output.append("="*60)
            
            output.append(f"ğŸŒ ç®€åŒ–ç‰ˆ: {access_url}")
            output.append(f"ğŸŒ å®Œæ•´ç‰ˆ: {full_url}")
            output.append(f"ğŸ“Š æå–ä¿¡æ¯: {info_url}")
            output.append("="*60)
            output.append("")
            output.append(f"âœ… æ“ä½œå®Œæˆï¼ç›´æ¥è®¿é—®åœ°å€: {access_url}")
            return "\n".join(output)
        else:
            return access_url
    else:
        return f"âŒ å…‹éš†å¤±è´¥: {result['error']}"


def process_single_url(
    server_url: str, 
    target_url: str, 
    output_file: Optional[str] = None,
    retries: int = 3,
    delay: int = 2
) -> bool:
    """å¤„ç†å•ä¸ªURLå…‹éš†"""
    result = send_clone_request(server_url, target_url, retries=retries, delay=delay)
    output = format_result(result)
    
    print(output)
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(output)
        print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return result['success']


def process_batch_urls(
    server_url: str, 
    file_path: str, 
    output_file: Optional[str] = None,
    retries: int = 3,
    delay: int = 2
) -> bool:
    """å¤„ç†æ‰¹é‡URLå…‹éš†"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except Exception as e:
        print(f"âŒ è¯»å–URLæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False
    
    if not urls:
        print("âŒ URLåˆ—è¡¨æ–‡ä»¶ä¸ºç©º")
        return False
    
    print(f"ğŸ“‹ å…±åŠ è½½ {len(urls)} ä¸ªURL")
    print()
    
    results = []
    success_count = 0
    fail_count = 0
    
    for i, url in enumerate(urls, 1):
        print(f"ğŸ“Œ å¤„ç† URL {i}/{len(urls)}: {url}")
        print("-" * 60)
        
        result = send_clone_request(server_url, url, retries=retries, delay=delay)
        results.append(result)
        
        if result['success']:
            success_count += 1
        else:
            fail_count += 1
        
        print(format_result(result))
        print()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("=" * 60)
    print("ğŸ“Š æ‰¹é‡å¤„ç†ç»Ÿè®¡:")
    print(f"âœ… æˆåŠŸ: {success_count} ä¸ª")
    print(f"âŒ å¤±è´¥: {fail_count} ä¸ª")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {(success_count / len(urls) * 100):.1f}%")
    print("=" * 60)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            for i, (url, result) in enumerate(zip(urls, results), 1):
                f.write(f"# URL {i}: {url}\n")
                if result['success']:
                    # ç›´æ¥ä½¿ç”¨æœåŠ¡å™¨è¿”å›çš„URL
                    f.write(f"æˆåŠŸ: {result['result']['access_url']}\n")
                else:
                    f.write(f"å¤±è´¥: {result['error']}\n")
                f.write("\n")
            
            # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
            f.write("=" * 60 + "\n")
            f.write("æ‰¹é‡å¤„ç†ç»Ÿè®¡:\n")
            f.write(f"æˆåŠŸ: {success_count} ä¸ª\n")
            f.write(f"å¤±è´¥: {fail_count} ä¸ª\n")
            f.write(f"æˆåŠŸç‡: {(success_count / len(urls) * 100):.1f}%\n")
        
        print(f"\nï¿½ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return success_count > 0


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='å‘ç½‘é¡µå…‹éš†å·¥å…·å‘é€URLå…‹éš†è¯·æ±‚çš„è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\nç¤ºä¾‹ç”¨æ³•:\n  python send_clone_request.py http://localhost:5001 https://example.com\n  python send_clone_request.py http://localhost:5001 --file urls.txt\n  python send_clone_request.py http://localhost:5001 https://example.com --output result.txt\n"""
    )
    
    parser.add_argument('server_url', help='å…‹éš†æœåŠ¡å™¨çš„URL')
    parser.add_argument('target_url', nargs='?', help='ç›®æ ‡å…‹éš†URLï¼ˆä¸--fileäºŒé€‰ä¸€ï¼‰')
    parser.add_argument('--file', '-f', help='åŒ…å«URLåˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='ä¿å­˜ç»“æœçš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--retries', '-r', type=int, default=3, help='è¯·æ±‚å¤±è´¥é‡è¯•æ¬¡æ•°')
    parser.add_argument('--delay', '-d', type=int, default=2, help='é‡è¯•é—´éš”ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å‚æ•°æœ‰æ•ˆæ€§
    if not (args.target_url or args.file):
        parser.error('å¿…é¡»æä¾› target_url æˆ– --file å‚æ•°')
    
    if args.target_url and args.file:
        parser.error('target_url å’Œ --file å‚æ•°ä¸èƒ½åŒæ—¶ä½¿ç”¨')
    
    success = False
    
    if args.target_url:
        # å¤„ç†å•ä¸ªURL
        success = process_single_url(
            args.server_url, 
            args.target_url, 
            args.output,
            retries=args.retries,
            delay=args.delay
        )
    else:
        # å¤„ç†æ‰¹é‡URL
        success = process_batch_urls(
            args.server_url, 
            args.file, 
            args.output,
            retries=args.retries,
            delay=args.delay
        )
    
    # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
